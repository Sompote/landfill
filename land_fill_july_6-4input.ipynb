{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.3)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch Pillow numpy torchvision scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-Nuc8waQY9En"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1, Batch:    6] loss: 4.112204\n",
      "[Epoch:1] Test Loss: 3.257634, MAPE: 1.384\n",
      "[Epoch:2, Batch:    6] loss: 3.517065\n",
      "[Epoch:2] Test Loss: 3.155608, MAPE: 1.471\n",
      "[Epoch:3, Batch:    6] loss: 3.068827\n",
      "[Epoch:3] Test Loss: 2.976534, MAPE: 1.480\n",
      "[Epoch:4, Batch:    6] loss: 2.606535\n",
      "[Epoch:4] Test Loss: 2.876922, MAPE: 1.489\n",
      "[Epoch:5, Batch:    6] loss: 2.333251\n",
      "[Epoch:5] Test Loss: 2.877463, MAPE: 1.497\n",
      "[Epoch:6, Batch:    6] loss: 2.092264\n",
      "[Epoch:6] Test Loss: 2.702188, MAPE: 1.448\n",
      "[Epoch:7, Batch:    6] loss: 1.897218\n",
      "[Epoch:7] Test Loss: 2.478241, MAPE: 1.451\n",
      "[Epoch:8, Batch:    6] loss: 1.644187\n",
      "[Epoch:8] Test Loss: 2.442180, MAPE: 1.402\n",
      "[Epoch:9, Batch:    6] loss: 1.544693\n",
      "[Epoch:9] Test Loss: 2.465771, MAPE: 1.356\n",
      "[Epoch:10, Batch:    6] loss: 1.682400\n",
      "[Epoch:10] Test Loss: 2.326406, MAPE: 1.295\n",
      "[Epoch:11, Batch:    6] loss: 1.371160\n",
      "[Epoch:11] Test Loss: 1.994399, MAPE: 1.226\n",
      "[Epoch:12, Batch:    6] loss: 1.187909\n",
      "[Epoch:12] Test Loss: 1.921717, MAPE: 1.201\n",
      "[Epoch:13, Batch:    6] loss: 1.097747\n",
      "[Epoch:13] Test Loss: 1.683966, MAPE: 1.152\n",
      "[Epoch:14, Batch:    6] loss: 1.043669\n",
      "[Epoch:14] Test Loss: 1.724607, MAPE: 1.143\n",
      "[Epoch:15, Batch:    6] loss: 0.940630\n",
      "[Epoch:15] Test Loss: 1.710241, MAPE: 1.123\n",
      "[Epoch:16, Batch:    6] loss: 0.900555\n",
      "[Epoch:16] Test Loss: 1.743037, MAPE: 1.087\n",
      "[Epoch:17, Batch:    6] loss: 0.851250\n",
      "[Epoch:17] Test Loss: 1.679310, MAPE: 1.081\n",
      "[Epoch:18, Batch:    6] loss: 0.875186\n",
      "[Epoch:18] Test Loss: 1.513632, MAPE: 1.064\n",
      "[Epoch:19, Batch:    6] loss: 0.717953\n",
      "[Epoch:19] Test Loss: 1.397275, MAPE: 1.040\n",
      "[Epoch:20, Batch:    6] loss: 0.671073\n",
      "[Epoch:20] Test Loss: 1.350755, MAPE: 1.026\n",
      "[Epoch:21, Batch:    6] loss: 0.733130\n",
      "[Epoch:21] Test Loss: 1.319940, MAPE: 1.003\n",
      "[Epoch:22, Batch:    6] loss: 0.681187\n",
      "[Epoch:22] Test Loss: 1.280209, MAPE: 1.013\n",
      "[Epoch:23, Batch:    6] loss: 0.644075\n",
      "[Epoch:23] Test Loss: 1.228083, MAPE: 0.962\n",
      "[Epoch:24, Batch:    6] loss: 0.705519\n",
      "[Epoch:24] Test Loss: 1.241781, MAPE: 0.992\n",
      "[Epoch:25, Batch:    6] loss: 0.656124\n",
      "[Epoch:25] Test Loss: 1.255870, MAPE: 1.022\n",
      "[Epoch:26, Batch:    6] loss: 0.612237\n",
      "[Epoch:26] Test Loss: 1.200363, MAPE: 0.984\n",
      "[Epoch:27, Batch:    6] loss: 0.588317\n",
      "[Epoch:27] Test Loss: 1.301619, MAPE: 1.028\n",
      "[Epoch:28, Batch:    6] loss: 0.581361\n",
      "[Epoch:28] Test Loss: 1.196684, MAPE: 0.996\n",
      "[Epoch:29, Batch:    6] loss: 0.559724\n",
      "[Epoch:29] Test Loss: 1.212099, MAPE: 0.983\n",
      "[Epoch:30, Batch:    6] loss: 0.636544\n",
      "[Epoch:30] Test Loss: 1.246515, MAPE: 0.960\n",
      "[Epoch:31, Batch:    6] loss: 0.489322\n",
      "[Epoch:31] Test Loss: 1.135037, MAPE: 0.912\n",
      "[Epoch:32, Batch:    6] loss: 0.607680\n",
      "[Epoch:32] Test Loss: 1.230557, MAPE: 0.978\n",
      "[Epoch:33, Batch:    6] loss: 0.448275\n",
      "[Epoch:33] Test Loss: 1.486638, MAPE: 1.037\n",
      "[Epoch:34, Batch:    6] loss: 0.493249\n",
      "[Epoch:34] Test Loss: 1.278159, MAPE: 0.987\n",
      "[Epoch:35, Batch:    6] loss: 0.542500\n",
      "[Epoch:35] Test Loss: 1.290164, MAPE: 0.998\n",
      "[Epoch:36, Batch:    6] loss: 0.475930\n",
      "[Epoch:36] Test Loss: 1.055857, MAPE: 0.920\n",
      "[Epoch:37, Batch:    6] loss: 0.439667\n",
      "[Epoch:37] Test Loss: 1.016931, MAPE: 0.871\n",
      "[Epoch:38, Batch:    6] loss: 0.453294\n",
      "[Epoch:38] Test Loss: 1.070371, MAPE: 0.893\n",
      "[Epoch:39, Batch:    6] loss: 0.417521\n",
      "[Epoch:39] Test Loss: 1.059723, MAPE: 0.907\n",
      "[Epoch:40, Batch:    6] loss: 0.402333\n",
      "[Epoch:40] Test Loss: 1.051156, MAPE: 0.898\n",
      "[Epoch:41, Batch:    6] loss: 0.433449\n",
      "[Epoch:41] Test Loss: 1.073930, MAPE: 0.898\n",
      "[Epoch:42, Batch:    6] loss: 0.380227\n",
      "[Epoch:42] Test Loss: 1.073268, MAPE: 0.889\n",
      "[Epoch:43, Batch:    6] loss: 0.418154\n",
      "[Epoch:43] Test Loss: 1.084518, MAPE: 0.898\n",
      "[Epoch:44, Batch:    6] loss: 0.662664\n",
      "[Epoch:44] Test Loss: 1.038939, MAPE: 0.874\n",
      "[Epoch:45, Batch:    6] loss: 0.389890\n",
      "[Epoch:45] Test Loss: 1.075536, MAPE: 0.913\n",
      "[Epoch:46, Batch:    6] loss: 0.414028\n",
      "[Epoch:46] Test Loss: 1.060826, MAPE: 0.925\n",
      "[Epoch:47, Batch:    6] loss: 0.419481\n",
      "[Epoch:47] Test Loss: 1.074100, MAPE: 0.948\n",
      "[Epoch:48, Batch:    6] loss: 0.470905\n",
      "[Epoch:48] Test Loss: 1.035113, MAPE: 0.918\n",
      "[Epoch:49, Batch:    6] loss: 0.516698\n",
      "[Epoch:49] Test Loss: 1.126528, MAPE: 0.926\n",
      "[Epoch:50, Batch:    6] loss: 0.440710\n",
      "[Epoch:50] Test Loss: 1.113326, MAPE: 0.924\n",
      "[Epoch:51, Batch:    6] loss: 0.341227\n",
      "[Epoch:51] Test Loss: 1.031446, MAPE: 0.859\n",
      "[Epoch:52, Batch:    6] loss: 0.440327\n",
      "[Epoch:52] Test Loss: 1.021398, MAPE: 0.884\n",
      "[Epoch:53, Batch:    6] loss: 0.403344\n",
      "[Epoch:53] Test Loss: 1.060606, MAPE: 0.911\n",
      "[Epoch:54, Batch:    6] loss: 0.374101\n",
      "[Epoch:54] Test Loss: 1.044927, MAPE: 0.931\n",
      "[Epoch:55, Batch:    6] loss: 0.376058\n",
      "[Epoch:55] Test Loss: 1.034337, MAPE: 0.920\n",
      "[Epoch:56, Batch:    6] loss: 0.364060\n",
      "[Epoch:56] Test Loss: 1.004086, MAPE: 0.882\n",
      "[Epoch:57, Batch:    6] loss: 0.391695\n",
      "[Epoch:57] Test Loss: 0.976893, MAPE: 0.862\n",
      "[Epoch:58, Batch:    6] loss: 0.367199\n",
      "[Epoch:58] Test Loss: 0.988108, MAPE: 0.842\n",
      "[Epoch:59, Batch:    6] loss: 0.415966\n",
      "[Epoch:59] Test Loss: 1.056757, MAPE: 0.882\n",
      "[Epoch:60, Batch:    6] loss: 0.338063\n",
      "[Epoch:60] Test Loss: 1.014690, MAPE: 0.861\n",
      "[Epoch:61, Batch:    6] loss: 0.485187\n",
      "[Epoch:61] Test Loss: 1.003372, MAPE: 0.864\n",
      "[Epoch:62, Batch:    6] loss: 0.383694\n",
      "[Epoch:62] Test Loss: 1.033425, MAPE: 0.919\n",
      "[Epoch:63, Batch:    6] loss: 0.363577\n",
      "[Epoch:63] Test Loss: 1.010894, MAPE: 0.864\n",
      "[Epoch:64, Batch:    6] loss: 0.319026\n",
      "[Epoch:64] Test Loss: 1.045135, MAPE: 0.879\n",
      "[Epoch:65, Batch:    6] loss: 0.329766\n",
      "[Epoch:65] Test Loss: 1.006786, MAPE: 0.889\n",
      "[Epoch:66, Batch:    6] loss: 0.356782\n",
      "[Epoch:66] Test Loss: 0.955131, MAPE: 0.855\n",
      "[Epoch:67, Batch:    6] loss: 0.364535\n",
      "[Epoch:67] Test Loss: 0.943917, MAPE: 0.818\n",
      "[Epoch:68, Batch:    6] loss: 0.329906\n",
      "[Epoch:68] Test Loss: 0.955398, MAPE: 0.832\n",
      "[Epoch:69, Batch:    6] loss: 0.314582\n",
      "[Epoch:69] Test Loss: 0.983807, MAPE: 0.844\n",
      "[Epoch:70, Batch:    6] loss: 0.298035\n",
      "[Epoch:70] Test Loss: 0.997267, MAPE: 0.866\n",
      "[Epoch:71, Batch:    6] loss: 0.355094\n",
      "[Epoch:71] Test Loss: 0.990051, MAPE: 0.889\n",
      "[Epoch:72, Batch:    6] loss: 0.341897\n",
      "[Epoch:72] Test Loss: 0.973912, MAPE: 0.888\n",
      "[Epoch:73, Batch:    6] loss: 0.293571\n",
      "[Epoch:73] Test Loss: 0.959063, MAPE: 0.863\n",
      "[Epoch:74, Batch:    6] loss: 0.364814\n",
      "[Epoch:74] Test Loss: 0.974128, MAPE: 0.869\n",
      "[Epoch:75, Batch:    6] loss: 0.278477\n",
      "[Epoch:75] Test Loss: 0.974721, MAPE: 0.875\n",
      "[Epoch:76, Batch:    6] loss: 0.289601\n",
      "[Epoch:76] Test Loss: 0.975328, MAPE: 0.877\n",
      "[Epoch:77, Batch:    6] loss: 0.320201\n",
      "[Epoch:77] Test Loss: 0.962546, MAPE: 0.874\n",
      "[Epoch:78, Batch:    6] loss: 0.338955\n",
      "[Epoch:78] Test Loss: 0.966621, MAPE: 0.901\n",
      "[Epoch:79, Batch:    6] loss: 0.311237\n",
      "[Epoch:79] Test Loss: 0.959426, MAPE: 0.872\n",
      "[Epoch:80, Batch:    6] loss: 0.297063\n",
      "[Epoch:80] Test Loss: 0.972961, MAPE: 0.860\n",
      "[Epoch:81, Batch:    6] loss: 0.352667\n",
      "[Epoch:81] Test Loss: 0.966418, MAPE: 0.840\n",
      "[Epoch:82, Batch:    6] loss: 0.271433\n",
      "[Epoch:82] Test Loss: 0.971943, MAPE: 0.855\n",
      "[Epoch:83, Batch:    6] loss: 0.378491\n",
      "[Epoch:83] Test Loss: 0.984640, MAPE: 0.902\n",
      "[Epoch:84, Batch:    6] loss: 0.303232\n",
      "[Epoch:84] Test Loss: 0.980040, MAPE: 0.928\n",
      "[Epoch:85, Batch:    6] loss: 0.361480\n",
      "[Epoch:85] Test Loss: 0.957456, MAPE: 0.883\n",
      "[Epoch:86, Batch:    6] loss: 0.304146\n",
      "[Epoch:86] Test Loss: 0.932537, MAPE: 0.835\n",
      "[Epoch:87, Batch:    6] loss: 0.303857\n",
      "[Epoch:87] Test Loss: 0.975696, MAPE: 0.882\n",
      "[Epoch:88, Batch:    6] loss: 0.286880\n",
      "[Epoch:88] Test Loss: 0.974452, MAPE: 0.888\n",
      "[Epoch:89, Batch:    6] loss: 0.303025\n",
      "[Epoch:89] Test Loss: 0.974960, MAPE: 0.875\n",
      "[Epoch:90, Batch:    6] loss: 0.314162\n",
      "[Epoch:90] Test Loss: 0.965097, MAPE: 0.877\n",
      "[Epoch:91, Batch:    6] loss: 0.309823\n",
      "[Epoch:91] Test Loss: 0.946553, MAPE: 0.843\n",
      "[Epoch:92, Batch:    6] loss: 0.289451\n",
      "[Epoch:92] Test Loss: 0.958070, MAPE: 0.861\n",
      "[Epoch:93, Batch:    6] loss: 0.333211\n",
      "[Epoch:93] Test Loss: 0.973067, MAPE: 0.913\n",
      "[Epoch:94, Batch:    6] loss: 0.313097\n",
      "[Epoch:94] Test Loss: 1.000125, MAPE: 0.905\n",
      "[Epoch:95, Batch:    6] loss: 0.310737\n",
      "[Epoch:95] Test Loss: 0.969167, MAPE: 0.889\n",
      "[Epoch:96, Batch:    6] loss: 0.276632\n",
      "[Epoch:96] Test Loss: 0.957794, MAPE: 0.872\n",
      "[Epoch:97, Batch:    6] loss: 0.258481\n",
      "[Epoch:97] Test Loss: 0.958554, MAPE: 0.853\n",
      "[Epoch:98, Batch:    6] loss: 0.265761\n",
      "[Epoch:98] Test Loss: 0.966942, MAPE: 0.917\n",
      "[Epoch:99, Batch:    6] loss: 0.270687\n",
      "[Epoch:99] Test Loss: 0.956133, MAPE: 0.903\n",
      "[Epoch:100, Batch:    6] loss: 0.307586\n",
      "[Epoch:100] Test Loss: 0.959766, MAPE: 0.873\n",
      "[Epoch:101, Batch:    6] loss: 0.269588\n",
      "[Epoch:101] Test Loss: 0.981360, MAPE: 0.892\n",
      "[Epoch:102, Batch:    6] loss: 0.294938\n",
      "[Epoch:102] Test Loss: 0.985960, MAPE: 0.919\n",
      "[Epoch:103, Batch:    6] loss: 0.287741\n",
      "[Epoch:103] Test Loss: 0.970113, MAPE: 0.886\n",
      "[Epoch:104, Batch:    6] loss: 0.235905\n",
      "[Epoch:104] Test Loss: 0.935776, MAPE: 0.865\n",
      "[Epoch:105, Batch:    6] loss: 0.265514\n",
      "[Epoch:105] Test Loss: 0.943367, MAPE: 0.868\n",
      "[Epoch:106, Batch:    6] loss: 0.259392\n",
      "[Epoch:106] Test Loss: 0.948028, MAPE: 0.816\n",
      "[Epoch:107, Batch:    6] loss: 0.254348\n",
      "[Epoch:107] Test Loss: 0.948683, MAPE: 0.853\n",
      "[Epoch:108, Batch:    6] loss: 0.243577\n",
      "[Epoch:108] Test Loss: 0.943980, MAPE: 0.843\n",
      "[Epoch:109, Batch:    6] loss: 0.222326\n",
      "[Epoch:109] Test Loss: 0.965148, MAPE: 0.871\n",
      "[Epoch:110, Batch:    6] loss: 0.245276\n",
      "[Epoch:110] Test Loss: 0.957207, MAPE: 0.889\n",
      "[Epoch:111, Batch:    6] loss: 0.234861\n",
      "[Epoch:111] Test Loss: 0.938911, MAPE: 0.847\n",
      "[Epoch:112, Batch:    6] loss: 0.238329\n",
      "[Epoch:112] Test Loss: 0.955445, MAPE: 0.866\n",
      "[Epoch:113, Batch:    6] loss: 0.198828\n",
      "[Epoch:113] Test Loss: 0.934337, MAPE: 0.854\n",
      "[Epoch:114, Batch:    6] loss: 0.265200\n",
      "[Epoch:114] Test Loss: 0.927645, MAPE: 0.851\n",
      "[Epoch:115, Batch:    6] loss: 0.261907\n",
      "[Epoch:115] Test Loss: 0.952874, MAPE: 0.878\n",
      "[Epoch:116, Batch:    6] loss: 0.245689\n",
      "[Epoch:116] Test Loss: 0.932270, MAPE: 0.841\n",
      "[Epoch:117, Batch:    6] loss: 0.240694\n",
      "[Epoch:117] Test Loss: 0.946351, MAPE: 0.873\n",
      "[Epoch:118, Batch:    6] loss: 0.222659\n",
      "[Epoch:118] Test Loss: 0.935189, MAPE: 0.859\n",
      "[Epoch:119, Batch:    6] loss: 0.204906\n",
      "[Epoch:119] Test Loss: 0.938496, MAPE: 0.869\n",
      "[Epoch:120, Batch:    6] loss: 0.215813\n",
      "[Epoch:120] Test Loss: 0.913184, MAPE: 0.827\n",
      "[Epoch:121, Batch:    6] loss: 0.211438\n",
      "[Epoch:121] Test Loss: 0.949427, MAPE: 0.902\n",
      "[Epoch:122, Batch:    6] loss: 0.250553\n",
      "[Epoch:122] Test Loss: 0.943095, MAPE: 0.904\n",
      "[Epoch:123, Batch:    6] loss: 0.207497\n",
      "[Epoch:123] Test Loss: 0.930599, MAPE: 0.876\n",
      "[Epoch:124, Batch:    6] loss: 0.278469\n",
      "[Epoch:124] Test Loss: 0.973104, MAPE: 0.925\n",
      "[Epoch:125, Batch:    6] loss: 0.176725\n",
      "[Epoch:125] Test Loss: 0.979330, MAPE: 0.897\n",
      "[Epoch:126, Batch:    6] loss: 0.202883\n",
      "[Epoch:126] Test Loss: 0.967711, MAPE: 0.918\n",
      "[Epoch:127, Batch:    6] loss: 0.197757\n",
      "[Epoch:127] Test Loss: 0.957663, MAPE: 0.914\n",
      "[Epoch:128, Batch:    6] loss: 0.209611\n",
      "[Epoch:128] Test Loss: 0.932781, MAPE: 0.863\n",
      "[Epoch:129, Batch:    6] loss: 0.207367\n",
      "[Epoch:129] Test Loss: 0.923205, MAPE: 0.874\n",
      "[Epoch:130, Batch:    6] loss: 0.230590\n",
      "[Epoch:130] Test Loss: 0.955532, MAPE: 0.914\n",
      "[Epoch:131, Batch:    6] loss: 0.183544\n",
      "[Epoch:131] Test Loss: 0.974358, MAPE: 0.916\n",
      "[Epoch:132, Batch:    6] loss: 0.210251\n",
      "[Epoch:132] Test Loss: 0.934470, MAPE: 0.851\n",
      "[Epoch:133, Batch:    6] loss: 0.222362\n",
      "[Epoch:133] Test Loss: 0.944386, MAPE: 0.859\n",
      "[Epoch:134, Batch:    6] loss: 0.200991\n",
      "[Epoch:134] Test Loss: 0.947107, MAPE: 0.879\n",
      "[Epoch:135, Batch:    6] loss: 0.187908\n",
      "[Epoch:135] Test Loss: 0.959106, MAPE: 0.922\n",
      "[Epoch:136, Batch:    6] loss: 0.446338\n",
      "[Epoch:136] Test Loss: 0.958365, MAPE: 0.936\n",
      "[Epoch:137, Batch:    6] loss: 0.264746\n",
      "[Epoch:137] Test Loss: 0.934793, MAPE: 0.872\n",
      "[Epoch:138, Batch:    6] loss: 0.233447\n",
      "[Epoch:138] Test Loss: 0.930670, MAPE: 0.842\n",
      "[Epoch:139, Batch:    6] loss: 0.219090\n",
      "[Epoch:139] Test Loss: 0.936905, MAPE: 0.833\n",
      "[Epoch:140, Batch:    6] loss: 0.248360\n",
      "[Epoch:140] Test Loss: 0.912424, MAPE: 0.820\n",
      "[Epoch:141, Batch:    6] loss: 0.201407\n",
      "[Epoch:141] Test Loss: 0.899339, MAPE: 0.773\n",
      "[Epoch:142, Batch:    6] loss: 0.157864\n",
      "[Epoch:142] Test Loss: 0.974957, MAPE: 0.798\n",
      "[Epoch:143, Batch:    6] loss: 0.216361\n",
      "[Epoch:143] Test Loss: 0.988191, MAPE: 0.830\n",
      "[Epoch:144, Batch:    6] loss: 0.214015\n",
      "[Epoch:144] Test Loss: 0.992957, MAPE: 0.894\n",
      "[Epoch:145, Batch:    6] loss: 0.194369\n",
      "[Epoch:145] Test Loss: 0.951111, MAPE: 0.887\n",
      "[Epoch:146, Batch:    6] loss: 0.171538\n",
      "[Epoch:146] Test Loss: 0.950409, MAPE: 0.901\n",
      "[Epoch:147, Batch:    6] loss: 0.212493\n",
      "[Epoch:147] Test Loss: 0.910858, MAPE: 0.862\n",
      "[Epoch:148, Batch:    6] loss: 0.155812\n",
      "[Epoch:148] Test Loss: 0.924586, MAPE: 0.888\n",
      "[Epoch:149, Batch:    6] loss: 0.232782\n",
      "[Epoch:149] Test Loss: 0.954509, MAPE: 0.932\n",
      "[Epoch:150, Batch:    6] loss: 0.217858\n",
      "[Epoch:150] Test Loss: 0.970539, MAPE: 0.922\n",
      "[Epoch:151, Batch:    6] loss: 0.164431\n",
      "[Epoch:151] Test Loss: 0.959070, MAPE: 0.909\n",
      "[Epoch:152, Batch:    6] loss: 0.147078\n",
      "[Epoch:152] Test Loss: 0.949143, MAPE: 0.920\n",
      "[Epoch:153, Batch:    6] loss: 0.149445\n",
      "[Epoch:153] Test Loss: 0.958600, MAPE: 0.923\n",
      "[Epoch:154, Batch:    6] loss: 0.197904\n",
      "[Epoch:154] Test Loss: 0.941999, MAPE: 0.888\n",
      "[Epoch:155, Batch:    6] loss: 0.299885\n",
      "[Epoch:155] Test Loss: 0.977595, MAPE: 0.970\n",
      "[Epoch:156, Batch:    6] loss: 0.185116\n",
      "[Epoch:156] Test Loss: 0.928690, MAPE: 0.879\n",
      "[Epoch:157, Batch:    6] loss: 0.215601\n",
      "[Epoch:157] Test Loss: 0.936930, MAPE: 0.908\n",
      "[Epoch:158, Batch:    6] loss: 0.167792\n",
      "[Epoch:158] Test Loss: 0.930024, MAPE: 0.933\n",
      "[Epoch:159, Batch:    6] loss: 0.179122\n",
      "[Epoch:159] Test Loss: 0.906812, MAPE: 0.908\n",
      "[Epoch:160, Batch:    6] loss: 0.124265\n",
      "[Epoch:160] Test Loss: 0.917925, MAPE: 0.906\n",
      "[Epoch:161, Batch:    6] loss: 0.181842\n",
      "[Epoch:161] Test Loss: 0.912442, MAPE: 0.903\n",
      "[Epoch:162, Batch:    6] loss: 0.142475\n",
      "[Epoch:162] Test Loss: 0.918840, MAPE: 0.901\n",
      "[Epoch:163, Batch:    6] loss: 0.344794\n",
      "[Epoch:163] Test Loss: 0.943080, MAPE: 0.933\n",
      "[Epoch:164, Batch:    6] loss: 0.184474\n",
      "[Epoch:164] Test Loss: 0.940223, MAPE: 0.943\n",
      "[Epoch:165, Batch:    6] loss: 0.143279\n",
      "[Epoch:165] Test Loss: 0.899269, MAPE: 0.876\n",
      "[Epoch:166, Batch:    6] loss: 0.165873\n",
      "[Epoch:166] Test Loss: 0.907310, MAPE: 0.854\n",
      "[Epoch:167, Batch:    6] loss: 0.146701\n",
      "[Epoch:167] Test Loss: 0.949158, MAPE: 0.902\n",
      "[Epoch:168, Batch:    6] loss: 0.199200\n",
      "[Epoch:168] Test Loss: 0.922900, MAPE: 0.865\n",
      "[Epoch:169, Batch:    6] loss: 0.127813\n",
      "[Epoch:169] Test Loss: 0.914169, MAPE: 0.877\n",
      "[Epoch:170, Batch:    6] loss: 0.176526\n",
      "[Epoch:170] Test Loss: 0.922752, MAPE: 0.846\n",
      "[Epoch:171, Batch:    6] loss: 0.142455\n",
      "[Epoch:171] Test Loss: 0.913072, MAPE: 0.854\n",
      "[Epoch:172, Batch:    6] loss: 0.159441\n",
      "[Epoch:172] Test Loss: 0.918635, MAPE: 0.884\n",
      "[Epoch:173, Batch:    6] loss: 0.176182\n",
      "[Epoch:173] Test Loss: 0.922153, MAPE: 0.879\n",
      "[Epoch:174, Batch:    6] loss: 0.171826\n",
      "[Epoch:174] Test Loss: 0.902505, MAPE: 0.897\n",
      "[Epoch:175, Batch:    6] loss: 0.217291\n",
      "[Epoch:175] Test Loss: 0.911496, MAPE: 0.901\n",
      "[Epoch:176, Batch:    6] loss: 0.176521\n",
      "[Epoch:176] Test Loss: 0.916754, MAPE: 0.899\n",
      "[Epoch:177, Batch:    6] loss: 0.144173\n",
      "[Epoch:177] Test Loss: 0.909613, MAPE: 0.870\n",
      "[Epoch:178, Batch:    6] loss: 0.139188\n",
      "[Epoch:178] Test Loss: 0.904182, MAPE: 0.875\n",
      "[Epoch:179, Batch:    6] loss: 0.202064\n",
      "[Epoch:179] Test Loss: 0.938332, MAPE: 0.941\n",
      "[Epoch:180, Batch:    6] loss: 0.163212\n",
      "[Epoch:180] Test Loss: 0.925446, MAPE: 0.923\n",
      "[Epoch:181, Batch:    6] loss: 0.140968\n",
      "[Epoch:181] Test Loss: 0.906750, MAPE: 0.912\n",
      "[Epoch:182, Batch:    6] loss: 0.148862\n",
      "[Epoch:182] Test Loss: 0.913300, MAPE: 0.904\n",
      "[Epoch:183, Batch:    6] loss: 0.137836\n",
      "[Epoch:183] Test Loss: 0.930044, MAPE: 0.902\n",
      "[Epoch:184, Batch:    6] loss: 0.158953\n",
      "[Epoch:184] Test Loss: 0.943333, MAPE: 0.925\n",
      "[Epoch:185, Batch:    6] loss: 0.134052\n",
      "[Epoch:185] Test Loss: 0.918237, MAPE: 0.889\n",
      "[Epoch:186, Batch:    6] loss: 0.138499\n",
      "[Epoch:186] Test Loss: 0.918736, MAPE: 0.905\n",
      "[Epoch:187, Batch:    6] loss: 0.153232\n",
      "[Epoch:187] Test Loss: 0.912862, MAPE: 0.908\n",
      "[Epoch:188, Batch:    6] loss: 0.167882\n",
      "[Epoch:188] Test Loss: 0.908772, MAPE: 0.897\n",
      "[Epoch:189, Batch:    6] loss: 0.144676\n",
      "[Epoch:189] Test Loss: 0.915136, MAPE: 0.919\n",
      "[Epoch:190, Batch:    6] loss: 0.124430\n",
      "[Epoch:190] Test Loss: 0.926035, MAPE: 0.930\n",
      "[Epoch:191, Batch:    6] loss: 0.142989\n",
      "[Epoch:191] Test Loss: 0.910828, MAPE: 0.904\n",
      "[Epoch:192, Batch:    6] loss: 0.167952\n",
      "[Epoch:192] Test Loss: 0.918283, MAPE: 0.903\n",
      "[Epoch:193, Batch:    6] loss: 0.157044\n",
      "[Epoch:193] Test Loss: 0.951307, MAPE: 0.949\n",
      "[Epoch:194, Batch:    6] loss: 0.154384\n",
      "[Epoch:194] Test Loss: 0.946289, MAPE: 0.936\n",
      "[Epoch:195, Batch:    6] loss: 0.126068\n",
      "[Epoch:195] Test Loss: 0.932235, MAPE: 0.911\n",
      "[Epoch:196, Batch:    6] loss: 0.153177\n",
      "[Epoch:196] Test Loss: 0.921495, MAPE: 0.898\n",
      "[Epoch:197, Batch:    6] loss: 0.156816\n",
      "[Epoch:197] Test Loss: 0.937271, MAPE: 0.917\n",
      "[Epoch:198, Batch:    6] loss: 0.151964\n",
      "[Epoch:198] Test Loss: 0.901497, MAPE: 0.880\n",
      "[Epoch:199, Batch:    6] loss: 0.130029\n",
      "[Epoch:199] Test Loss: 0.926102, MAPE: 0.876\n",
      "[Epoch:200, Batch:    6] loss: 0.175496\n",
      "[Epoch:200] Test Loss: 0.930795, MAPE: 0.900\n",
      "[Epoch:201, Batch:    6] loss: 0.130591\n",
      "[Epoch:201] Test Loss: 0.919252, MAPE: 0.895\n",
      "[Epoch:202, Batch:    6] loss: 0.174392\n",
      "[Epoch:202] Test Loss: 0.901591, MAPE: 0.876\n",
      "[Epoch:203, Batch:    6] loss: 0.114203\n",
      "[Epoch:203] Test Loss: 0.943066, MAPE: 0.919\n",
      "[Epoch:204, Batch:    6] loss: 0.131748\n",
      "[Epoch:204] Test Loss: 0.921559, MAPE: 0.907\n",
      "[Epoch:205, Batch:    6] loss: 0.217870\n",
      "[Epoch:205] Test Loss: 0.891261, MAPE: 0.872\n",
      "[Epoch:206, Batch:    6] loss: 0.155342\n",
      "[Epoch:206] Test Loss: 0.906575, MAPE: 0.906\n",
      "[Epoch:207, Batch:    6] loss: 0.173849\n",
      "[Epoch:207] Test Loss: 0.920869, MAPE: 0.901\n",
      "[Epoch:208, Batch:    6] loss: 0.126467\n",
      "[Epoch:208] Test Loss: 0.926428, MAPE: 0.883\n",
      "[Epoch:209, Batch:    6] loss: 0.151002\n",
      "[Epoch:209] Test Loss: 0.931289, MAPE: 0.916\n",
      "[Epoch:210, Batch:    6] loss: 0.113297\n",
      "[Epoch:210] Test Loss: 0.942963, MAPE: 0.929\n",
      "[Epoch:211, Batch:    6] loss: 0.113291\n",
      "[Epoch:211] Test Loss: 0.940032, MAPE: 0.929\n",
      "[Epoch:212, Batch:    6] loss: 0.114886\n",
      "[Epoch:212] Test Loss: 0.918280, MAPE: 0.899\n",
      "[Epoch:213, Batch:    6] loss: 0.295686\n",
      "[Epoch:213] Test Loss: 0.914218, MAPE: 0.904\n",
      "[Epoch:214, Batch:    6] loss: 0.136423\n",
      "[Epoch:214] Test Loss: 0.977770, MAPE: 0.969\n",
      "[Epoch:215, Batch:    6] loss: 0.151112\n",
      "[Epoch:215] Test Loss: 0.961786, MAPE: 0.942\n",
      "[Epoch:216, Batch:    6] loss: 0.182215\n",
      "[Epoch:216] Test Loss: 0.925146, MAPE: 0.888\n",
      "[Epoch:217, Batch:    6] loss: 0.124359\n",
      "[Epoch:217] Test Loss: 0.949245, MAPE: 0.922\n",
      "[Epoch:218, Batch:    6] loss: 0.159511\n",
      "[Epoch:218] Test Loss: 0.946454, MAPE: 0.916\n",
      "[Epoch:219, Batch:    6] loss: 0.117613\n",
      "[Epoch:219] Test Loss: 0.949383, MAPE: 0.911\n",
      "[Epoch:220, Batch:    6] loss: 0.141790\n",
      "[Epoch:220] Test Loss: 0.940928, MAPE: 0.916\n",
      "[Epoch:221, Batch:    6] loss: 0.144003\n",
      "[Epoch:221] Test Loss: 0.939190, MAPE: 0.936\n",
      "[Epoch:222, Batch:    6] loss: 0.153114\n",
      "[Epoch:222] Test Loss: 0.936573, MAPE: 0.925\n",
      "[Epoch:223, Batch:    6] loss: 0.126046\n",
      "[Epoch:223] Test Loss: 0.927072, MAPE: 0.903\n",
      "[Epoch:224, Batch:    6] loss: 0.190241\n",
      "[Epoch:224] Test Loss: 0.938118, MAPE: 0.914\n",
      "[Epoch:225, Batch:    6] loss: 0.167086\n",
      "[Epoch:225] Test Loss: 0.960285, MAPE: 0.962\n",
      "[Epoch:226, Batch:    6] loss: 0.106361\n",
      "[Epoch:226] Test Loss: 0.972386, MAPE: 0.970\n",
      "[Epoch:227, Batch:    6] loss: 0.172192\n",
      "[Epoch:227] Test Loss: 0.942877, MAPE: 0.937\n",
      "[Epoch:228, Batch:    6] loss: 0.117168\n",
      "[Epoch:228] Test Loss: 0.930112, MAPE: 0.896\n",
      "[Epoch:229, Batch:    6] loss: 0.178819\n",
      "[Epoch:229] Test Loss: 0.949449, MAPE: 0.928\n",
      "[Epoch:230, Batch:    6] loss: 0.122089\n",
      "[Epoch:230] Test Loss: 0.943505, MAPE: 0.911\n",
      "[Epoch:231, Batch:    6] loss: 0.131465\n",
      "[Epoch:231] Test Loss: 0.927038, MAPE: 0.893\n",
      "[Epoch:232, Batch:    6] loss: 0.110286\n",
      "[Epoch:232] Test Loss: 0.942158, MAPE: 0.899\n",
      "[Epoch:233, Batch:    6] loss: 0.175327\n",
      "[Epoch:233] Test Loss: 0.924038, MAPE: 0.881\n",
      "[Epoch:234, Batch:    6] loss: 0.099397\n",
      "[Epoch:234] Test Loss: 0.925118, MAPE: 0.883\n",
      "[Epoch:235, Batch:    6] loss: 0.103557\n",
      "[Epoch:235] Test Loss: 0.929622, MAPE: 0.887\n",
      "[Epoch:236, Batch:    6] loss: 0.116941\n",
      "[Epoch:236] Test Loss: 0.935327, MAPE: 0.898\n",
      "[Epoch:237, Batch:    6] loss: 0.103007\n",
      "[Epoch:237] Test Loss: 0.929281, MAPE: 0.901\n",
      "[Epoch:238, Batch:    6] loss: 0.114844\n",
      "[Epoch:238] Test Loss: 0.930396, MAPE: 0.895\n",
      "[Epoch:239, Batch:    6] loss: 0.118580\n",
      "[Epoch:239] Test Loss: 0.931641, MAPE: 0.882\n",
      "[Epoch:240, Batch:    6] loss: 0.126798\n",
      "[Epoch:240] Test Loss: 0.940712, MAPE: 0.897\n",
      "[Epoch:241, Batch:    6] loss: 0.123118\n",
      "[Epoch:241] Test Loss: 0.934891, MAPE: 0.886\n",
      "[Epoch:242, Batch:    6] loss: 0.112842\n",
      "[Epoch:242] Test Loss: 0.934846, MAPE: 0.898\n",
      "[Epoch:243, Batch:    6] loss: 0.124295\n",
      "[Epoch:243] Test Loss: 0.919770, MAPE: 0.902\n",
      "[Epoch:244, Batch:    6] loss: 0.097200\n",
      "[Epoch:244] Test Loss: 0.922033, MAPE: 0.923\n",
      "[Epoch:245, Batch:    6] loss: 0.143528\n",
      "[Epoch:245] Test Loss: 0.915731, MAPE: 0.905\n",
      "[Epoch:246, Batch:    6] loss: 0.153388\n",
      "[Epoch:246] Test Loss: 0.954768, MAPE: 0.952\n",
      "[Epoch:247, Batch:    6] loss: 0.129624\n",
      "[Epoch:247] Test Loss: 0.967780, MAPE: 0.952\n",
      "[Epoch:248, Batch:    6] loss: 0.100113\n",
      "[Epoch:248] Test Loss: 0.964417, MAPE: 0.936\n",
      "[Epoch:249, Batch:    6] loss: 0.117153\n",
      "[Epoch:249] Test Loss: 0.944204, MAPE: 0.925\n",
      "[Epoch:250, Batch:    6] loss: 0.101851\n",
      "[Epoch:250] Test Loss: 0.952401, MAPE: 0.930\n",
      "[Epoch:251, Batch:    6] loss: 0.155753\n",
      "[Epoch:251] Test Loss: 0.953576, MAPE: 0.952\n",
      "[Epoch:252, Batch:    6] loss: 0.115916\n",
      "[Epoch:252] Test Loss: 0.920494, MAPE: 0.876\n",
      "[Epoch:253, Batch:    6] loss: 0.127686\n",
      "[Epoch:253] Test Loss: 0.925465, MAPE: 0.884\n",
      "[Epoch:254, Batch:    6] loss: 0.118637\n",
      "[Epoch:254] Test Loss: 0.923134, MAPE: 0.890\n",
      "[Epoch:255, Batch:    6] loss: 0.122641\n",
      "[Epoch:255] Test Loss: 0.940151, MAPE: 0.921\n",
      "[Epoch:256, Batch:    6] loss: 0.112342\n",
      "[Epoch:256] Test Loss: 0.938555, MAPE: 0.921\n",
      "[Epoch:257, Batch:    6] loss: 0.120544\n",
      "[Epoch:257] Test Loss: 0.948166, MAPE: 0.931\n",
      "[Epoch:258, Batch:    6] loss: 0.113258\n",
      "[Epoch:258] Test Loss: 0.955463, MAPE: 0.944\n",
      "[Epoch:259, Batch:    6] loss: 0.124532\n",
      "[Epoch:259] Test Loss: 0.963323, MAPE: 0.937\n",
      "[Epoch:260, Batch:    6] loss: 0.146797\n",
      "[Epoch:260] Test Loss: 0.971201, MAPE: 0.957\n",
      "[Epoch:261, Batch:    6] loss: 0.116368\n",
      "[Epoch:261] Test Loss: 0.936006, MAPE: 0.924\n",
      "[Epoch:262, Batch:    6] loss: 0.174861\n",
      "[Epoch:262] Test Loss: 0.901499, MAPE: 0.861\n",
      "[Epoch:263, Batch:    6] loss: 0.118428\n",
      "[Epoch:263] Test Loss: 0.913864, MAPE: 0.883\n",
      "[Epoch:264, Batch:    6] loss: 0.121576\n",
      "[Epoch:264] Test Loss: 0.923005, MAPE: 0.892\n",
      "[Epoch:265, Batch:    6] loss: 0.137954\n",
      "[Epoch:265] Test Loss: 0.932523, MAPE: 0.899\n",
      "[Epoch:266, Batch:    6] loss: 0.228322\n",
      "[Epoch:266] Test Loss: 0.934130, MAPE: 0.924\n",
      "[Epoch:267, Batch:    6] loss: 0.126974\n",
      "[Epoch:267] Test Loss: 0.938080, MAPE: 0.926\n",
      "[Epoch:268, Batch:    6] loss: 0.173228\n",
      "[Epoch:268] Test Loss: 0.955338, MAPE: 0.939\n",
      "[Epoch:269, Batch:    6] loss: 0.113916\n",
      "[Epoch:269] Test Loss: 0.957631, MAPE: 0.913\n",
      "[Epoch:270, Batch:    6] loss: 0.110896\n",
      "[Epoch:270] Test Loss: 0.947649, MAPE: 0.920\n",
      "[Epoch:271, Batch:    6] loss: 0.125892\n",
      "[Epoch:271] Test Loss: 0.947543, MAPE: 0.933\n",
      "[Epoch:272, Batch:    6] loss: 0.114194\n",
      "[Epoch:272] Test Loss: 0.943864, MAPE: 0.916\n",
      "[Epoch:273, Batch:    6] loss: 0.155876\n",
      "[Epoch:273] Test Loss: 0.924378, MAPE: 0.891\n",
      "[Epoch:274, Batch:    6] loss: 0.119958\n",
      "[Epoch:274] Test Loss: 0.931979, MAPE: 0.888\n",
      "[Epoch:275, Batch:    6] loss: 0.111455\n",
      "[Epoch:275] Test Loss: 0.923366, MAPE: 0.882\n",
      "[Epoch:276, Batch:    6] loss: 0.108403\n",
      "[Epoch:276] Test Loss: 0.944287, MAPE: 0.908\n",
      "[Epoch:277, Batch:    6] loss: 0.102445\n",
      "[Epoch:277] Test Loss: 0.938791, MAPE: 0.904\n",
      "[Epoch:278, Batch:    6] loss: 0.125919\n",
      "[Epoch:278] Test Loss: 0.934597, MAPE: 0.900\n",
      "[Epoch:279, Batch:    6] loss: 0.134635\n",
      "[Epoch:279] Test Loss: 0.950223, MAPE: 0.920\n",
      "[Epoch:280, Batch:    6] loss: 0.125178\n",
      "[Epoch:280] Test Loss: 0.956104, MAPE: 0.926\n",
      "[Epoch:281, Batch:    6] loss: 0.108625\n",
      "[Epoch:281] Test Loss: 0.935268, MAPE: 0.918\n",
      "[Epoch:282, Batch:    6] loss: 0.148773\n",
      "[Epoch:282] Test Loss: 0.941013, MAPE: 0.926\n",
      "[Epoch:283, Batch:    6] loss: 0.112910\n",
      "[Epoch:283] Test Loss: 0.970834, MAPE: 0.954\n",
      "[Epoch:284, Batch:    6] loss: 0.102724\n",
      "[Epoch:284] Test Loss: 0.948815, MAPE: 0.945\n",
      "[Epoch:285, Batch:    6] loss: 0.105168\n",
      "[Epoch:285] Test Loss: 0.949095, MAPE: 0.935\n",
      "[Epoch:286, Batch:    6] loss: 0.122302\n",
      "[Epoch:286] Test Loss: 0.924928, MAPE: 0.912\n",
      "[Epoch:287, Batch:    6] loss: 0.113645\n",
      "[Epoch:287] Test Loss: 0.912666, MAPE: 0.890\n",
      "[Epoch:288, Batch:    6] loss: 0.093976\n",
      "[Epoch:288] Test Loss: 0.926246, MAPE: 0.893\n",
      "[Epoch:289, Batch:    6] loss: 0.124261\n",
      "[Epoch:289] Test Loss: 0.925209, MAPE: 0.886\n",
      "[Epoch:290, Batch:    6] loss: 0.102098\n",
      "[Epoch:290] Test Loss: 0.938159, MAPE: 0.892\n",
      "[Epoch:291, Batch:    6] loss: 0.116356\n",
      "[Epoch:291] Test Loss: 0.966299, MAPE: 0.934\n",
      "[Epoch:292, Batch:    6] loss: 0.097340\n",
      "[Epoch:292] Test Loss: 0.959241, MAPE: 0.926\n",
      "[Epoch:293, Batch:    6] loss: 0.120498\n",
      "[Epoch:293] Test Loss: 0.947393, MAPE: 0.910\n",
      "[Epoch:294, Batch:    6] loss: 0.197323\n",
      "[Epoch:294] Test Loss: 0.970277, MAPE: 0.947\n",
      "[Epoch:295, Batch:    6] loss: 0.113329\n",
      "[Epoch:295] Test Loss: 0.966996, MAPE: 0.941\n",
      "[Epoch:296, Batch:    6] loss: 0.119299\n",
      "[Epoch:296] Test Loss: 0.944436, MAPE: 0.909\n",
      "[Epoch:297, Batch:    6] loss: 0.168040\n",
      "[Epoch:297] Test Loss: 0.969331, MAPE: 0.950\n",
      "[Epoch:298, Batch:    6] loss: 0.112947\n",
      "[Epoch:298] Test Loss: 0.951056, MAPE: 0.913\n",
      "[Epoch:299, Batch:    6] loss: 0.099782\n",
      "[Epoch:299] Test Loss: 0.919681, MAPE: 0.902\n",
      "[Epoch:300, Batch:    6] loss: 0.107198\n",
      "[Epoch:300] Test Loss: 0.911620, MAPE: 0.902\n",
      "[Epoch:301, Batch:    6] loss: 0.112888\n",
      "[Epoch:301] Test Loss: 0.925358, MAPE: 0.888\n",
      "[Epoch:302, Batch:    6] loss: 0.103326\n",
      "[Epoch:302] Test Loss: 0.930475, MAPE: 0.899\n",
      "[Epoch:303, Batch:    6] loss: 0.090692\n",
      "[Epoch:303] Test Loss: 0.947506, MAPE: 0.912\n",
      "[Epoch:304, Batch:    6] loss: 0.100016\n",
      "[Epoch:304] Test Loss: 0.942666, MAPE: 0.931\n",
      "[Epoch:305, Batch:    6] loss: 0.147014\n",
      "[Epoch:305] Test Loss: 0.948063, MAPE: 0.952\n",
      "[Epoch:306, Batch:    6] loss: 0.109413\n",
      "[Epoch:306] Test Loss: 0.919053, MAPE: 0.898\n",
      "[Epoch:307, Batch:    6] loss: 0.099712\n",
      "[Epoch:307] Test Loss: 0.920809, MAPE: 0.896\n",
      "[Epoch:308, Batch:    6] loss: 0.145107\n",
      "[Epoch:308] Test Loss: 0.928337, MAPE: 0.906\n",
      "[Epoch:309, Batch:    6] loss: 0.090890\n",
      "[Epoch:309] Test Loss: 0.944150, MAPE: 0.912\n",
      "[Epoch:310, Batch:    6] loss: 0.103748\n",
      "[Epoch:310] Test Loss: 0.938315, MAPE: 0.907\n",
      "[Epoch:311, Batch:    6] loss: 0.114151\n",
      "[Epoch:311] Test Loss: 0.912325, MAPE: 0.895\n",
      "[Epoch:312, Batch:    6] loss: 0.113498\n",
      "[Epoch:312] Test Loss: 0.910661, MAPE: 0.893\n",
      "[Epoch:313, Batch:    6] loss: 0.112596\n",
      "[Epoch:313] Test Loss: 0.930723, MAPE: 0.915\n",
      "[Epoch:314, Batch:    6] loss: 0.092363\n",
      "[Epoch:314] Test Loss: 0.945091, MAPE: 0.915\n",
      "[Epoch:315, Batch:    6] loss: 0.105025\n",
      "[Epoch:315] Test Loss: 0.930602, MAPE: 0.882\n",
      "[Epoch:316, Batch:    6] loss: 0.208122\n",
      "[Epoch:316] Test Loss: 0.939313, MAPE: 0.915\n",
      "[Epoch:317, Batch:    6] loss: 0.118500\n",
      "[Epoch:317] Test Loss: 0.916707, MAPE: 0.891\n",
      "[Epoch:318, Batch:    6] loss: 0.118404\n",
      "[Epoch:318] Test Loss: 0.918501, MAPE: 0.888\n",
      "[Epoch:319, Batch:    6] loss: 0.101043\n",
      "[Epoch:319] Test Loss: 0.899488, MAPE: 0.874\n",
      "[Epoch:320, Batch:    6] loss: 0.106162\n",
      "[Epoch:320] Test Loss: 0.890752, MAPE: 0.843\n",
      "[Epoch:321, Batch:    6] loss: 0.113542\n",
      "[Epoch:321] Test Loss: 0.899953, MAPE: 0.849\n",
      "[Epoch:322, Batch:    6] loss: 0.085300\n",
      "[Epoch:322] Test Loss: 0.913788, MAPE: 0.883\n",
      "[Epoch:323, Batch:    6] loss: 0.124949\n",
      "[Epoch:323] Test Loss: 0.904187, MAPE: 0.872\n",
      "[Epoch:324, Batch:    6] loss: 0.105673\n",
      "[Epoch:324] Test Loss: 0.900377, MAPE: 0.879\n",
      "[Epoch:325, Batch:    6] loss: 0.099957\n",
      "[Epoch:325] Test Loss: 0.904816, MAPE: 0.882\n",
      "[Epoch:326, Batch:    6] loss: 0.085262\n",
      "[Epoch:326] Test Loss: 0.921529, MAPE: 0.903\n",
      "[Epoch:327, Batch:    6] loss: 0.157618\n",
      "[Epoch:327] Test Loss: 0.934751, MAPE: 0.927\n",
      "[Epoch:328, Batch:    6] loss: 0.105088\n",
      "[Epoch:328] Test Loss: 0.910827, MAPE: 0.892\n",
      "[Epoch:329, Batch:    6] loss: 0.113154\n",
      "[Epoch:329] Test Loss: 0.937958, MAPE: 0.900\n",
      "[Epoch:330, Batch:    6] loss: 0.095689\n",
      "[Epoch:330] Test Loss: 0.924439, MAPE: 0.889\n",
      "[Epoch:331, Batch:    6] loss: 0.100557\n",
      "[Epoch:331] Test Loss: 0.927340, MAPE: 0.892\n",
      "[Epoch:332, Batch:    6] loss: 0.099347\n",
      "[Epoch:332] Test Loss: 0.929342, MAPE: 0.877\n",
      "[Epoch:333, Batch:    6] loss: 0.088500\n",
      "[Epoch:333] Test Loss: 0.938450, MAPE: 0.871\n",
      "[Epoch:334, Batch:    6] loss: 0.123639\n",
      "[Epoch:334] Test Loss: 0.933165, MAPE: 0.877\n",
      "[Epoch:335, Batch:    6] loss: 0.096329\n",
      "[Epoch:335] Test Loss: 0.925292, MAPE: 0.876\n",
      "[Epoch:336, Batch:    6] loss: 0.109369\n",
      "[Epoch:336] Test Loss: 0.927448, MAPE: 0.867\n",
      "[Epoch:337, Batch:    6] loss: 0.134509\n",
      "[Epoch:337] Test Loss: 0.945847, MAPE: 0.904\n",
      "[Epoch:338, Batch:    6] loss: 0.093193\n",
      "[Epoch:338] Test Loss: 0.932556, MAPE: 0.880\n",
      "[Epoch:339, Batch:    6] loss: 0.090145\n",
      "[Epoch:339] Test Loss: 0.933487, MAPE: 0.904\n",
      "[Epoch:340, Batch:    6] loss: 0.098695\n",
      "[Epoch:340] Test Loss: 0.926222, MAPE: 0.888\n",
      "[Epoch:341, Batch:    6] loss: 0.095910\n",
      "[Epoch:341] Test Loss: 0.929333, MAPE: 0.888\n",
      "[Epoch:342, Batch:    6] loss: 0.118727\n",
      "[Epoch:342] Test Loss: 0.926472, MAPE: 0.885\n",
      "[Epoch:343, Batch:    6] loss: 0.088616\n",
      "[Epoch:343] Test Loss: 0.931588, MAPE: 0.892\n",
      "[Epoch:344, Batch:    6] loss: 0.092415\n",
      "[Epoch:344] Test Loss: 0.930638, MAPE: 0.889\n",
      "[Epoch:345, Batch:    6] loss: 0.150965\n",
      "[Epoch:345] Test Loss: 0.942183, MAPE: 0.913\n",
      "[Epoch:346, Batch:    6] loss: 0.102516\n",
      "[Epoch:346] Test Loss: 0.930597, MAPE: 0.885\n",
      "[Epoch:347, Batch:    6] loss: 0.192084\n",
      "[Epoch:347] Test Loss: 0.951685, MAPE: 0.914\n",
      "[Epoch:348, Batch:    6] loss: 0.092099\n",
      "[Epoch:348] Test Loss: 0.957991, MAPE: 0.945\n",
      "[Epoch:349, Batch:    6] loss: 0.167144\n",
      "[Epoch:349] Test Loss: 0.976302, MAPE: 0.947\n",
      "[Epoch:350, Batch:    6] loss: 0.138590\n",
      "[Epoch:350] Test Loss: 0.964998, MAPE: 0.921\n",
      "[Epoch:351, Batch:    6] loss: 0.116461\n",
      "[Epoch:351] Test Loss: 0.942232, MAPE: 0.888\n",
      "[Epoch:352, Batch:    6] loss: 0.117923\n",
      "[Epoch:352] Test Loss: 0.962365, MAPE: 0.890\n",
      "[Epoch:353, Batch:    6] loss: 0.110120\n",
      "[Epoch:353] Test Loss: 0.962132, MAPE: 0.903\n",
      "[Epoch:354, Batch:    6] loss: 0.089884\n",
      "[Epoch:354] Test Loss: 0.946628, MAPE: 0.917\n",
      "[Epoch:355, Batch:    6] loss: 0.088129\n",
      "[Epoch:355] Test Loss: 0.935230, MAPE: 0.899\n",
      "[Epoch:356, Batch:    6] loss: 0.087491\n",
      "[Epoch:356] Test Loss: 0.936245, MAPE: 0.902\n",
      "[Epoch:357, Batch:    6] loss: 0.090485\n",
      "[Epoch:357] Test Loss: 0.933211, MAPE: 0.905\n",
      "[Epoch:358, Batch:    6] loss: 0.114928\n",
      "[Epoch:358] Test Loss: 0.917613, MAPE: 0.867\n",
      "[Epoch:359, Batch:    6] loss: 0.098250\n",
      "[Epoch:359] Test Loss: 0.914804, MAPE: 0.864\n",
      "[Epoch:360, Batch:    6] loss: 0.157796\n",
      "[Epoch:360] Test Loss: 0.937378, MAPE: 0.908\n",
      "[Epoch:361, Batch:    6] loss: 0.098957\n",
      "[Epoch:361] Test Loss: 0.928310, MAPE: 0.909\n",
      "[Epoch:362, Batch:    6] loss: 0.097147\n",
      "[Epoch:362] Test Loss: 0.931510, MAPE: 0.899\n",
      "[Epoch:363, Batch:    6] loss: 0.093909\n",
      "[Epoch:363] Test Loss: 0.937434, MAPE: 0.899\n",
      "[Epoch:364, Batch:    6] loss: 0.108958\n",
      "[Epoch:364] Test Loss: 0.929743, MAPE: 0.896\n",
      "[Epoch:365, Batch:    6] loss: 0.084330\n",
      "[Epoch:365] Test Loss: 0.946863, MAPE: 0.927\n",
      "[Epoch:366, Batch:    6] loss: 0.086542\n",
      "[Epoch:366] Test Loss: 0.932605, MAPE: 0.913\n",
      "[Epoch:367, Batch:    6] loss: 0.100717\n",
      "[Epoch:367] Test Loss: 0.937555, MAPE: 0.921\n",
      "[Epoch:368, Batch:    6] loss: 0.095574\n",
      "[Epoch:368] Test Loss: 0.928901, MAPE: 0.893\n",
      "[Epoch:369, Batch:    6] loss: 0.099572\n",
      "[Epoch:369] Test Loss: 0.920351, MAPE: 0.888\n",
      "[Epoch:370, Batch:    6] loss: 0.089910\n",
      "[Epoch:370] Test Loss: 0.924729, MAPE: 0.879\n",
      "[Epoch:371, Batch:    6] loss: 0.133434\n",
      "[Epoch:371] Test Loss: 0.923726, MAPE: 0.876\n",
      "[Epoch:372, Batch:    6] loss: 0.192000\n",
      "[Epoch:372] Test Loss: 0.947782, MAPE: 0.918\n",
      "[Epoch:373, Batch:    6] loss: 0.107635\n",
      "[Epoch:373] Test Loss: 0.950914, MAPE: 0.913\n",
      "[Epoch:374, Batch:    6] loss: 0.116587\n",
      "[Epoch:374] Test Loss: 0.927236, MAPE: 0.895\n",
      "[Epoch:375, Batch:    6] loss: 0.132972\n",
      "[Epoch:375] Test Loss: 0.897196, MAPE: 0.865\n",
      "[Epoch:376, Batch:    6] loss: 0.096718\n",
      "[Epoch:376] Test Loss: 0.919608, MAPE: 0.895\n",
      "[Epoch:377, Batch:    6] loss: 0.128663\n",
      "[Epoch:377] Test Loss: 0.913762, MAPE: 0.886\n",
      "[Epoch:378, Batch:    6] loss: 0.112011\n",
      "[Epoch:378] Test Loss: 0.918163, MAPE: 0.892\n",
      "[Epoch:379, Batch:    6] loss: 0.137936\n",
      "[Epoch:379] Test Loss: 0.923090, MAPE: 0.894\n",
      "[Epoch:380, Batch:    6] loss: 0.103882\n",
      "[Epoch:380] Test Loss: 0.901822, MAPE: 0.889\n",
      "[Epoch:381, Batch:    6] loss: 0.089523\n",
      "[Epoch:381] Test Loss: 0.904759, MAPE: 0.902\n",
      "[Epoch:382, Batch:    6] loss: 0.098634\n",
      "[Epoch:382] Test Loss: 0.913949, MAPE: 0.881\n",
      "[Epoch:383, Batch:    6] loss: 0.080766\n",
      "[Epoch:383] Test Loss: 0.912282, MAPE: 0.884\n",
      "[Epoch:384, Batch:    6] loss: 0.085495\n",
      "[Epoch:384] Test Loss: 0.936832, MAPE: 0.919\n",
      "[Epoch:385, Batch:    6] loss: 0.083970\n",
      "[Epoch:385] Test Loss: 0.922384, MAPE: 0.924\n",
      "[Epoch:386, Batch:    6] loss: 0.104719\n",
      "[Epoch:386] Test Loss: 0.923674, MAPE: 0.907\n",
      "[Epoch:387, Batch:    6] loss: 0.090238\n",
      "[Epoch:387] Test Loss: 0.919442, MAPE: 0.883\n",
      "[Epoch:388, Batch:    6] loss: 0.089978\n",
      "[Epoch:388] Test Loss: 0.927992, MAPE: 0.894\n",
      "[Epoch:389, Batch:    6] loss: 0.079841\n",
      "[Epoch:389] Test Loss: 0.936272, MAPE: 0.916\n",
      "[Epoch:390, Batch:    6] loss: 0.081748\n",
      "[Epoch:390] Test Loss: 0.940489, MAPE: 0.915\n",
      "[Epoch:391, Batch:    6] loss: 0.091375\n",
      "[Epoch:391] Test Loss: 0.931237, MAPE: 0.904\n",
      "[Epoch:392, Batch:    6] loss: 0.080427\n",
      "[Epoch:392] Test Loss: 0.920950, MAPE: 0.900\n",
      "[Epoch:393, Batch:    6] loss: 0.098132\n",
      "[Epoch:393] Test Loss: 0.936335, MAPE: 0.922\n",
      "[Epoch:394, Batch:    6] loss: 0.254443\n",
      "[Epoch:394] Test Loss: 0.946941, MAPE: 0.953\n",
      "[Epoch:395, Batch:    6] loss: 0.091876\n",
      "[Epoch:395] Test Loss: 0.920762, MAPE: 0.910\n",
      "[Epoch:396, Batch:    6] loss: 0.097571\n",
      "[Epoch:396] Test Loss: 0.911997, MAPE: 0.876\n",
      "[Epoch:397, Batch:    6] loss: 0.099004\n",
      "[Epoch:397] Test Loss: 0.917321, MAPE: 0.872\n",
      "[Epoch:398, Batch:    6] loss: 0.080824\n",
      "[Epoch:398] Test Loss: 0.934194, MAPE: 0.897\n",
      "[Epoch:399, Batch:    6] loss: 0.077358\n",
      "[Epoch:399] Test Loss: 0.931666, MAPE: 0.910\n",
      "[Epoch:400, Batch:    6] loss: 0.077611\n",
      "[Epoch:400] Test Loss: 0.932843, MAPE: 0.908\n",
      "[Epoch:401, Batch:    6] loss: 0.079855\n",
      "[Epoch:401] Test Loss: 0.919942, MAPE: 0.890\n",
      "[Epoch:402, Batch:    6] loss: 0.081785\n",
      "[Epoch:402] Test Loss: 0.924427, MAPE: 0.896\n",
      "[Epoch:403, Batch:    6] loss: 0.077103\n",
      "[Epoch:403] Test Loss: 0.930143, MAPE: 0.894\n",
      "[Epoch:404, Batch:    6] loss: 0.096501\n",
      "[Epoch:404] Test Loss: 0.907097, MAPE: 0.865\n",
      "[Epoch:405, Batch:    6] loss: 0.108570\n",
      "[Epoch:405] Test Loss: 0.945773, MAPE: 0.921\n",
      "[Epoch:406, Batch:    6] loss: 0.083614\n",
      "[Epoch:406] Test Loss: 0.944779, MAPE: 0.923\n",
      "[Epoch:407, Batch:    6] loss: 0.090551\n",
      "[Epoch:407] Test Loss: 0.935019, MAPE: 0.901\n",
      "[Epoch:408, Batch:    6] loss: 0.104009\n",
      "[Epoch:408] Test Loss: 0.937613, MAPE: 0.904\n",
      "[Epoch:409, Batch:    6] loss: 0.112774\n",
      "[Epoch:409] Test Loss: 0.922154, MAPE: 0.897\n",
      "[Epoch:410, Batch:    6] loss: 0.117241\n",
      "[Epoch:410] Test Loss: 0.919129, MAPE: 0.894\n",
      "[Epoch:411, Batch:    6] loss: 0.092194\n",
      "[Epoch:411] Test Loss: 0.928459, MAPE: 0.904\n",
      "[Epoch:412, Batch:    6] loss: 0.078992\n",
      "[Epoch:412] Test Loss: 0.933611, MAPE: 0.905\n",
      "[Epoch:413, Batch:    6] loss: 0.100596\n",
      "[Epoch:413] Test Loss: 0.913326, MAPE: 0.873\n",
      "[Epoch:414, Batch:    6] loss: 0.076027\n",
      "[Epoch:414] Test Loss: 0.917597, MAPE: 0.879\n",
      "[Epoch:415, Batch:    6] loss: 0.085206\n",
      "[Epoch:415] Test Loss: 0.917459, MAPE: 0.893\n",
      "[Epoch:416, Batch:    6] loss: 0.093695\n",
      "[Epoch:416] Test Loss: 0.922929, MAPE: 0.909\n",
      "[Epoch:417, Batch:    6] loss: 0.117298\n",
      "[Epoch:417] Test Loss: 0.914231, MAPE: 0.885\n",
      "[Epoch:418, Batch:    6] loss: 0.076507\n",
      "[Epoch:418] Test Loss: 0.922406, MAPE: 0.895\n",
      "[Epoch:419, Batch:    6] loss: 0.081147\n",
      "[Epoch:419] Test Loss: 0.913020, MAPE: 0.873\n",
      "[Epoch:420, Batch:    6] loss: 0.087511\n",
      "[Epoch:420] Test Loss: 0.929582, MAPE: 0.900\n",
      "[Epoch:421, Batch:    6] loss: 0.080412\n",
      "[Epoch:421] Test Loss: 0.924245, MAPE: 0.898\n",
      "[Epoch:422, Batch:    6] loss: 0.086403\n",
      "[Epoch:422] Test Loss: 0.927965, MAPE: 0.902\n",
      "[Epoch:423, Batch:    6] loss: 0.136717\n",
      "[Epoch:423] Test Loss: 0.948019, MAPE: 0.930\n",
      "[Epoch:424, Batch:    6] loss: 0.080580\n",
      "[Epoch:424] Test Loss: 0.941434, MAPE: 0.919\n",
      "[Epoch:425, Batch:    6] loss: 0.115264\n",
      "[Epoch:425] Test Loss: 0.935044, MAPE: 0.902\n",
      "[Epoch:426, Batch:    6] loss: 0.098157\n",
      "[Epoch:426] Test Loss: 0.923554, MAPE: 0.857\n",
      "[Epoch:427, Batch:    6] loss: 0.112855\n",
      "[Epoch:427] Test Loss: 0.949674, MAPE: 0.888\n",
      "[Epoch:428, Batch:    6] loss: 0.098505\n",
      "[Epoch:428] Test Loss: 0.932634, MAPE: 0.884\n",
      "[Epoch:429, Batch:    6] loss: 0.087282\n",
      "[Epoch:429] Test Loss: 0.916392, MAPE: 0.872\n",
      "[Epoch:430, Batch:    6] loss: 0.083367\n",
      "[Epoch:430] Test Loss: 0.924322, MAPE: 0.882\n",
      "[Epoch:431, Batch:    6] loss: 0.087733\n",
      "[Epoch:431] Test Loss: 0.901606, MAPE: 0.864\n",
      "[Epoch:432, Batch:    6] loss: 0.087969\n",
      "[Epoch:432] Test Loss: 0.909026, MAPE: 0.865\n",
      "[Epoch:433, Batch:    6] loss: 0.111313\n",
      "[Epoch:433] Test Loss: 0.923136, MAPE: 0.885\n",
      "[Epoch:434, Batch:    6] loss: 0.083155\n",
      "[Epoch:434] Test Loss: 0.934188, MAPE: 0.899\n",
      "[Epoch:435, Batch:    6] loss: 0.112826\n",
      "[Epoch:435] Test Loss: 0.956693, MAPE: 0.930\n",
      "[Epoch:436, Batch:    6] loss: 0.083365\n",
      "[Epoch:436] Test Loss: 0.950134, MAPE: 0.917\n",
      "[Epoch:437, Batch:    6] loss: 0.107377\n",
      "[Epoch:437] Test Loss: 0.957413, MAPE: 0.916\n",
      "[Epoch:438, Batch:    6] loss: 0.102068\n",
      "[Epoch:438] Test Loss: 0.938126, MAPE: 0.888\n",
      "[Epoch:439, Batch:    6] loss: 0.120907\n",
      "[Epoch:439] Test Loss: 0.949441, MAPE: 0.916\n",
      "[Epoch:440, Batch:    6] loss: 0.081030\n",
      "[Epoch:440] Test Loss: 0.929364, MAPE: 0.887\n",
      "[Epoch:441, Batch:    6] loss: 0.084582\n",
      "[Epoch:441] Test Loss: 0.932329, MAPE: 0.889\n",
      "[Epoch:442, Batch:    6] loss: 0.083376\n",
      "[Epoch:442] Test Loss: 0.922259, MAPE: 0.867\n",
      "[Epoch:443, Batch:    6] loss: 0.088188\n",
      "[Epoch:443] Test Loss: 0.919924, MAPE: 0.876\n",
      "[Epoch:444, Batch:    6] loss: 0.078728\n",
      "[Epoch:444] Test Loss: 0.925796, MAPE: 0.885\n",
      "[Epoch:445, Batch:    6] loss: 0.074465\n",
      "[Epoch:445] Test Loss: 0.931740, MAPE: 0.896\n",
      "[Epoch:446, Batch:    6] loss: 0.084495\n",
      "[Epoch:446] Test Loss: 0.928454, MAPE: 0.894\n",
      "[Epoch:447, Batch:    6] loss: 0.085454\n",
      "[Epoch:447] Test Loss: 0.928249, MAPE: 0.897\n",
      "[Epoch:448, Batch:    6] loss: 0.089795\n",
      "[Epoch:448] Test Loss: 0.919768, MAPE: 0.902\n",
      "[Epoch:449, Batch:    6] loss: 0.073771\n",
      "[Epoch:449] Test Loss: 0.911361, MAPE: 0.891\n",
      "[Epoch:450, Batch:    6] loss: 0.078344\n",
      "[Epoch:450] Test Loss: 0.935007, MAPE: 0.910\n",
      "[Epoch:451, Batch:    6] loss: 0.090353\n",
      "[Epoch:451] Test Loss: 0.936073, MAPE: 0.899\n",
      "[Epoch:452, Batch:    6] loss: 0.076611\n",
      "[Epoch:452] Test Loss: 0.951286, MAPE: 0.914\n",
      "[Epoch:453, Batch:    6] loss: 0.090672\n",
      "[Epoch:453] Test Loss: 0.941985, MAPE: 0.914\n",
      "[Epoch:454, Batch:    6] loss: 0.091223\n",
      "[Epoch:454] Test Loss: 0.946879, MAPE: 0.930\n",
      "[Epoch:455, Batch:    6] loss: 0.072953\n",
      "[Epoch:455] Test Loss: 0.945827, MAPE: 0.922\n",
      "[Epoch:456, Batch:    6] loss: 0.087398\n",
      "[Epoch:456] Test Loss: 0.922863, MAPE: 0.881\n",
      "[Epoch:457, Batch:    6] loss: 0.095645\n",
      "[Epoch:457] Test Loss: 0.940988, MAPE: 0.905\n",
      "[Epoch:458, Batch:    6] loss: 0.085330\n",
      "[Epoch:458] Test Loss: 0.935895, MAPE: 0.897\n",
      "[Epoch:459, Batch:    6] loss: 0.114507\n",
      "[Epoch:459] Test Loss: 0.949879, MAPE: 0.911\n",
      "[Epoch:460, Batch:    6] loss: 0.089218\n",
      "[Epoch:460] Test Loss: 0.966666, MAPE: 0.938\n",
      "[Epoch:461, Batch:    6] loss: 0.077106\n",
      "[Epoch:461] Test Loss: 0.955407, MAPE: 0.929\n",
      "[Epoch:462, Batch:    6] loss: 0.098795\n",
      "[Epoch:462] Test Loss: 0.922757, MAPE: 0.890\n",
      "[Epoch:463, Batch:    6] loss: 0.184902\n",
      "[Epoch:463] Test Loss: 0.946175, MAPE: 0.937\n",
      "[Epoch:464, Batch:    6] loss: 0.102105\n",
      "[Epoch:464] Test Loss: 0.911358, MAPE: 0.885\n",
      "[Epoch:465, Batch:    6] loss: 0.151130\n",
      "[Epoch:465] Test Loss: 0.930170, MAPE: 0.921\n",
      "[Epoch:466, Batch:    6] loss: 0.085941\n",
      "[Epoch:466] Test Loss: 0.927861, MAPE: 0.914\n",
      "[Epoch:467, Batch:    6] loss: 0.086721\n",
      "[Epoch:467] Test Loss: 0.921495, MAPE: 0.899\n",
      "[Epoch:468, Batch:    6] loss: 0.076692\n",
      "[Epoch:468] Test Loss: 0.920120, MAPE: 0.882\n",
      "[Epoch:469, Batch:    6] loss: 0.084982\n",
      "[Epoch:469] Test Loss: 0.913265, MAPE: 0.875\n",
      "[Epoch:470, Batch:    6] loss: 0.093752\n",
      "[Epoch:470] Test Loss: 0.908398, MAPE: 0.878\n",
      "[Epoch:471, Batch:    6] loss: 0.072262\n",
      "[Epoch:471] Test Loss: 0.916198, MAPE: 0.888\n",
      "[Epoch:472, Batch:    6] loss: 0.075331\n",
      "[Epoch:472] Test Loss: 0.918585, MAPE: 0.892\n",
      "[Epoch:473, Batch:    6] loss: 0.069466\n",
      "[Epoch:473] Test Loss: 0.909769, MAPE: 0.878\n",
      "[Epoch:474, Batch:    6] loss: 0.081474\n",
      "[Epoch:474] Test Loss: 0.908217, MAPE: 0.881\n",
      "[Epoch:475, Batch:    6] loss: 0.078305\n",
      "[Epoch:475] Test Loss: 0.913651, MAPE: 0.894\n",
      "[Epoch:476, Batch:    6] loss: 0.102574\n",
      "[Epoch:476] Test Loss: 0.915257, MAPE: 0.903\n",
      "[Epoch:477, Batch:    6] loss: 0.095135\n",
      "[Epoch:477] Test Loss: 0.891114, MAPE: 0.873\n",
      "[Epoch:478, Batch:    6] loss: 0.098661\n",
      "[Epoch:478] Test Loss: 0.946550, MAPE: 0.926\n",
      "[Epoch:479, Batch:    6] loss: 0.084764\n",
      "[Epoch:479] Test Loss: 0.947406, MAPE: 0.949\n",
      "[Epoch:480, Batch:    6] loss: 0.086977\n",
      "[Epoch:480] Test Loss: 0.927463, MAPE: 0.904\n",
      "[Epoch:481, Batch:    6] loss: 0.078714\n",
      "[Epoch:481] Test Loss: 0.928819, MAPE: 0.903\n",
      "[Epoch:482, Batch:    6] loss: 0.084187\n",
      "[Epoch:482] Test Loss: 0.931055, MAPE: 0.898\n",
      "[Epoch:483, Batch:    6] loss: 0.084561\n",
      "[Epoch:483] Test Loss: 0.910773, MAPE: 0.868\n",
      "[Epoch:484, Batch:    6] loss: 0.073134\n",
      "[Epoch:484] Test Loss: 0.917156, MAPE: 0.888\n",
      "[Epoch:485, Batch:    6] loss: 0.079488\n",
      "[Epoch:485] Test Loss: 0.918938, MAPE: 0.892\n",
      "[Epoch:486, Batch:    6] loss: 0.072599\n",
      "[Epoch:486] Test Loss: 0.915088, MAPE: 0.890\n",
      "[Epoch:487, Batch:    6] loss: 0.081685\n",
      "[Epoch:487] Test Loss: 0.906586, MAPE: 0.873\n",
      "[Epoch:488, Batch:    6] loss: 0.083146\n",
      "[Epoch:488] Test Loss: 0.916024, MAPE: 0.884\n",
      "[Epoch:489, Batch:    6] loss: 0.076185\n",
      "[Epoch:489] Test Loss: 0.912887, MAPE: 0.888\n",
      "[Epoch:490, Batch:    6] loss: 0.086325\n",
      "[Epoch:490] Test Loss: 0.920891, MAPE: 0.878\n",
      "[Epoch:491, Batch:    6] loss: 0.080728\n",
      "[Epoch:491] Test Loss: 0.926479, MAPE: 0.904\n",
      "[Epoch:492, Batch:    6] loss: 0.075058\n",
      "[Epoch:492] Test Loss: 0.933837, MAPE: 0.928\n",
      "[Epoch:493, Batch:    6] loss: 0.074379\n",
      "[Epoch:493] Test Loss: 0.928302, MAPE: 0.919\n",
      "[Epoch:494, Batch:    6] loss: 0.103419\n",
      "[Epoch:494] Test Loss: 0.949342, MAPE: 0.936\n",
      "[Epoch:495, Batch:    6] loss: 0.114934\n",
      "[Epoch:495] Test Loss: 0.953231, MAPE: 0.938\n",
      "[Epoch:496, Batch:    6] loss: 0.092717\n",
      "[Epoch:496] Test Loss: 0.926408, MAPE: 0.902\n",
      "[Epoch:497, Batch:    6] loss: 0.078495\n",
      "[Epoch:497] Test Loss: 0.919018, MAPE: 0.893\n",
      "[Epoch:498, Batch:    6] loss: 0.092058\n",
      "[Epoch:498] Test Loss: 0.913821, MAPE: 0.874\n",
      "[Epoch:499, Batch:    6] loss: 0.157056\n",
      "[Epoch:499] Test Loss: 0.925043, MAPE: 0.898\n",
      "[Epoch:500, Batch:    6] loss: 0.102362\n",
      "[Epoch:500] Test Loss: 0.926371, MAPE: 0.927\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Model()\\n# Input images (assume these are your 2-channel images)\\nimage1 = torch.randn(1, 1, 480, 480)\\nimage2 = torch.randn(1, 1, 480, 480)\\nimage3 = torch.randn(1, 1, 480, 480)\\n\\n# Pass images through the model\\noutput = model(image1, image2,image3)\\n\\n# Output will have shape [1, 3, 480, 480]\\nprint(output.shape)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code for 3 input picture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from torchvision.models import resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ResNet50Encoder(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(ResNet50Encoder, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50 model\n",
    "        self.resnet50 = resnet50(pretrained=True)\n",
    "        \n",
    "        # Replace the first convolution layer to accept a different number of channels\n",
    "        self.resnet50.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Remove the fully connected layer and the average pooling layer\n",
    "        self.resnet50 = nn.Sequential(*list(self.resnet50.children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "\n",
    "        # Define ResNet layers (modify based on your specific ResNet architecture)\n",
    "        self.resnet = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=20, stride=5, padding=1),\n",
    "            # Add more ResNet layers here...\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "class FNNReducer(nn.Module):\n",
    "    def __init__(self, input_size):  # Pass the input size here\n",
    "        super(FNNReducer, self).__init__()\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_size, out_features=1024),  # Use input_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 20 * 20),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "class CNNExpander(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNExpander, self).__init__()\n",
    "        self.conv_transpose = nn.ConvTranspose2d(\n",
    "            in_channels=8192,\n",
    "            out_channels=1,\n",
    "            kernel_size=34,\n",
    "            stride=32,\n",
    "            padding=1,\n",
    "            output_padding=0\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_transpose(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.resnet_encoder1 = ResNet50Encoder()\n",
    "        self.resnet_encoder2 = ResNet50Encoder()\n",
    "        self.resnet_encoder3 = ResNet50Encoder()\n",
    "        self.resnet_encoder4 = ResNet50Encoder()\n",
    "        \n",
    "\n",
    "        self.cnn_expander = CNNExpander()\n",
    "    \n",
    "    def forward(self, x1, x2, x3,x4):\n",
    "        # ResNet encoding\n",
    "        x1 = self.resnet_encoder1(x1)\n",
    "        x2 = self.resnet_encoder2(x2)\n",
    "        x3 = self.resnet_encoder3(x3)\n",
    "        x4 = self.resnet_encoder4(x4)\n",
    "\n",
    "        # Concatenate features\n",
    "        x = torch.cat((x1, x2,x3,x4), dim=1)  #concat at channal\n",
    "    \n",
    "        x = self.cnn_expander(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, input1_folder, input2_folder, input3_folder,input4_folder, output_folder, transform=None):\n",
    "        self.input1_folder = input1_folder\n",
    "        self.input2_folder = input2_folder\n",
    "        self.input3_folder = input3_folder\n",
    "        self.input4_folder = input4_folder\n",
    "        self.output_folder = output_folder\n",
    "       \n",
    "        # Filter filenames where only the first letter is a number\n",
    "        self.input1_filenames = sorted([f for f in os.listdir(input1_folder) if f[0].isdigit()])\n",
    "        self.input2_filenames = sorted([f for f in os.listdir(input2_folder) if f[0].isdigit()])\n",
    "        self.input3_filenames = sorted([f for f in os.listdir(input3_folder) if f[0].isdigit()])\n",
    "        self.input4_filenames = sorted([f for f in os.listdir(input4_folder) if f[0].isdigit()])\n",
    "        self.output_filenames = sorted([f for f in os.listdir(output_folder) if f[0].isdigit()])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input1_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input1_path = os.path.join(self.input1_folder, self.input1_filenames[idx])\n",
    "        input2_path = os.path.join(self.input2_folder, self.input2_filenames[idx])\n",
    "        input3_path = os.path.join(self.input3_folder, self.input3_filenames[idx])\n",
    "        input4_path = os.path.join(self.input4_folder, self.input3_filenames[idx])\n",
    "        output_path = os.path.join(self.output_folder, self.output_filenames[idx])\n",
    "\n",
    "        input1 = Image.open(input1_path).convert('L')\n",
    "        input2 = Image.open(input2_path).convert('L')\n",
    "        input3 = Image.open(input3_path).convert('L')\n",
    "        input4 = Image.open(input3_path).convert('L')\n",
    "        output = Image.open(output_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            input1 = self.transform(input1)\n",
    "            input2 = self.transform(input2)\n",
    "            input3 = self.transform(input3)\n",
    "            input4 = self.transform(input4)\n",
    "            output = self.transform(output)\n",
    "\n",
    "        return input1, input2,  input3, input4, output\n",
    "\n",
    "# Define the training function\n",
    "def train(model, train_dataloader, test_dataloader, optimizer, criterion, epochs,l2_lambda=1e-5):\n",
    "    # CUDA Usage:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move the model to the GPU\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set the model to training mode\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            input1, input2, input3, input4, target = data\n",
    "            input1 = input1.to(device)\n",
    "            input2 = input2.to(device)\n",
    "            input3 = input3.to(device)\n",
    "            input4 = input4.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(input1, input2,input3, input4)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "            # Add L2 regularization term\n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += l2_lambda * l2_reg\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "           \n",
    "            \n",
    "        train_losses.append(running_loss / len(train_dataloader))\n",
    "        print(f'[Epoch:{epoch + 1}, Batch:{i + 1:5d}] loss: {running_loss/len(train_dataloader):.6f}')\n",
    "\n",
    "        # Evaluation phase (after each epoch)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            all_predictions = []\n",
    "            all_targets = []\n",
    "            for input1, input2, input3, input4, target in test_dataloader:\n",
    "                input1 = input1.to(device)\n",
    "                input2 = input2.to(device)\n",
    "                input3 = input3.to(device)\n",
    "                input4 = input4.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                # Predict using the model\n",
    "                output = model(input1, input2,input3,input4)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = criterion(output, target)\n",
    "                # Add L2 regularization term (same as in training)\n",
    "                l2_reg = torch.tensor(0.).to(device)\n",
    "                for param in model.parameters():\n",
    "                    l2_reg += torch.norm(param)\n",
    "                loss += l2_lambda * l2_reg\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Store predictions and targets for MAPE calculation\n",
    "                all_predictions.append(output.cpu().numpy())\n",
    "                all_targets.append(target.cpu().numpy())\n",
    "\n",
    "            # Calculate MAPE\n",
    "            all_predictions = np.concatenate(all_predictions).flatten() # Flatten the array\n",
    "            all_targets = np.concatenate(all_targets).flatten() # Flatten the array\n",
    "            mape = mean_absolute_percentage_error(all_targets, all_predictions)\n",
    "\n",
    "            # Print evaluation results\n",
    "            test_losses.append(test_loss / len(test_dataloader))\n",
    "            print(f'[Epoch:{epoch + 1}] Test Loss: {test_loss / len(test_dataloader):.6f}, MAPE: {mape:.3f}')\n",
    "\n",
    "    # Plot train and test losses\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Define the training function (same as before)\n",
    "# ... (code for train)\n",
    "\n",
    "\n",
    "\n",
    "# Set paths to your input and output folders\n",
    "input1_folder = '/workspace/AI-Thermal'  # Replace with your actual path\n",
    "input2_folder = '/workspace/AI-EC/EC-0.5'  # Replace with your actual path\n",
    "input3_folder = '/workspace/AI-EC/EC-1.5'  # Replace with your actual path\n",
    "input4_folder = '/workspace/AI-EC/EC-5.0'  # Replace with your actual path\n",
    "output_folder = '/workspace/AI-CH4 flux' # Replace with your actual path\n",
    "\n",
    "# Define data transformations (e.g., normalization, resizing)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    \n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ImageDataset(input1_folder, input2_folder, input3_folder,input4_folder,\n",
    "                       output_folder, transform=transform)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Use batch size 1 for test\n",
    "\n",
    "\n",
    "# Create the model, optimizer, and loss function\n",
    "model = Model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "#criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "train(model, train_dataloader, test_dataloader, optimizer, criterion, epochs=500,l2_lambda=1e-5)\n",
    "\n",
    "'''\n",
    "model = Model()\n",
    "# Input images (assume these are your 2-channel images)\n",
    "image1 = torch.randn(1, 1, 480, 480)\n",
    "image2 = torch.randn(1, 1, 480, 480)\n",
    "image3 = torch.randn(1, 1, 480, 480)\n",
    "\n",
    "# Pass images through the model\n",
    "output = model(image1, image2,image3)\n",
    "\n",
    "# Output will have shape [1, 3, 480, 480]\n",
    "print(output.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jPelaLvl4dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Model                                              [1, 1, 480, 480]          --\n",
       "ResNet50Encoder: 1-1                             [1, 2048, 15, 15]         --\n",
       "    Sequential: 2-1                             [1, 2048, 15, 15]         --\n",
       "        Conv2d: 3-1                            [1, 64, 240, 240]         3,136\n",
       "        BatchNorm2d: 3-2                       [1, 64, 240, 240]         128\n",
       "        ReLU: 3-3                              [1, 64, 240, 240]         --\n",
       "        MaxPool2d: 3-4                         [1, 64, 120, 120]         --\n",
       "        Sequential: 3-5                        [1, 256, 120, 120]        215,808\n",
       "        Sequential: 3-6                        [1, 512, 60, 60]          1,219,584\n",
       "        Sequential: 3-7                        [1, 1024, 30, 30]         7,098,368\n",
       "        Sequential: 3-8                        [1, 2048, 15, 15]         14,964,736\n",
       "ResNet50Encoder: 1-2                             [1, 2048, 15, 15]         --\n",
       "    Sequential: 2-2                             [1, 2048, 15, 15]         --\n",
       "        Conv2d: 3-9                            [1, 64, 240, 240]         3,136\n",
       "        BatchNorm2d: 3-10                      [1, 64, 240, 240]         128\n",
       "        ReLU: 3-11                             [1, 64, 240, 240]         --\n",
       "        MaxPool2d: 3-12                        [1, 64, 120, 120]         --\n",
       "        Sequential: 3-13                       [1, 256, 120, 120]        215,808\n",
       "        Sequential: 3-14                       [1, 512, 60, 60]          1,219,584\n",
       "        Sequential: 3-15                       [1, 1024, 30, 30]         7,098,368\n",
       "        Sequential: 3-16                       [1, 2048, 15, 15]         14,964,736\n",
       "ResNet50Encoder: 1-3                             [1, 2048, 15, 15]         --\n",
       "    Sequential: 2-3                             [1, 2048, 15, 15]         --\n",
       "        Conv2d: 3-17                           [1, 64, 240, 240]         3,136\n",
       "        BatchNorm2d: 3-18                      [1, 64, 240, 240]         128\n",
       "        ReLU: 3-19                             [1, 64, 240, 240]         --\n",
       "        MaxPool2d: 3-20                        [1, 64, 120, 120]         --\n",
       "        Sequential: 3-21                       [1, 256, 120, 120]        215,808\n",
       "        Sequential: 3-22                       [1, 512, 60, 60]          1,219,584\n",
       "        Sequential: 3-23                       [1, 1024, 30, 30]         7,098,368\n",
       "        Sequential: 3-24                       [1, 2048, 15, 15]         14,964,736\n",
       "ResNet50Encoder: 1-4                             [1, 2048, 15, 15]         --\n",
       "    Sequential: 2-4                             [1, 2048, 15, 15]         --\n",
       "        Conv2d: 3-25                           [1, 64, 240, 240]         3,136\n",
       "        BatchNorm2d: 3-26                      [1, 64, 240, 240]         128\n",
       "        ReLU: 3-27                             [1, 64, 240, 240]         --\n",
       "        MaxPool2d: 3-28                        [1, 64, 120, 120]         --\n",
       "        Sequential: 3-29                       [1, 256, 120, 120]        215,808\n",
       "        Sequential: 3-30                       [1, 512, 60, 60]          1,219,584\n",
       "        Sequential: 3-31                       [1, 1024, 30, 30]         7,098,368\n",
       "        Sequential: 3-32                       [1, 2048, 15, 15]         14,964,736\n",
       "CNNExpander: 1-5                                 [1, 1, 480, 480]          --\n",
       "    ConvTranspose2d: 2-5                        [1, 1, 480, 480]          9,469,953\n",
       "====================================================================================================\n",
       "Total params: 103,476,993\n",
       "Trainable params: 103,476,993\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 2.26\n",
       "====================================================================================================\n",
       "Input size (MB): 3.69\n",
       "Forward/backward pass size (MB): 3267.99\n",
       "Params size (MB): 413.91\n",
       "Estimated Total Size (MB): 3685.59\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Print a detailed summary of the model\n",
    "summary(model, input_size=[(1, 1, 480, 480), (1, 1, 480, 480), (1, 1, 480, 480),(1, 1, 480, 480)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
